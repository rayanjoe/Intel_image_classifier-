{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc731d1d",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-11-21T23:47:47.106276Z",
     "iopub.status.busy": "2023-11-21T23:47:47.105992Z",
     "iopub.status.idle": "2023-11-21T23:47:48.536431Z",
     "shell.execute_reply": "2023-11-21T23:47:48.535685Z"
    },
    "papermill": {
     "duration": 1.437395,
     "end_time": "2023-11-21T23:47:48.538167",
     "exception": false,
     "start_time": "2023-11-21T23:47:47.100772",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/csc-578-final-project-fall-2023/lsst-train.csv\n",
      "/kaggle/input/csc-578-final-project-fall-2023/lsst-test.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fb7821",
   "metadata": {
    "papermill": {
     "duration": 0.00356,
     "end_time": "2023-11-21T23:47:48.545843",
     "exception": false,
     "start_time": "2023-11-21T23:47:48.542283",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "First read in the training set as you normally do/did.  My suggestion is to read it into a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d5865f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T23:47:48.556119Z",
     "iopub.status.busy": "2023-11-21T23:47:48.555751Z",
     "iopub.status.idle": "2023-11-21T23:47:48.822574Z",
     "shell.execute_reply": "2023-11-21T23:47:48.821529Z"
    },
    "papermill": {
     "duration": 0.275157,
     "end_time": "2023-11-21T23:47:48.824700",
     "exception": false,
     "start_time": "2023-11-21T23:47:48.549543",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "parent_train_ = pd.read_csv(\"/kaggle/input/csc-578-final-project-fall-2023/lsst-train.csv\")\n",
    "parent_test = pd.read_csv(\"/kaggle/input/csc-578-final-project-fall-2023/lsst-test.csv\")\n",
    "parent_train = parent_train_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ee33b1",
   "metadata": {
    "papermill": {
     "duration": 0.003969,
     "end_time": "2023-11-21T23:47:48.832675",
     "exception": false,
     "start_time": "2023-11-21T23:47:48.828706",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "You must convert the target column ('target'; y) to integers.\n",
    "\n",
    "- The integers should be the 0-based indices of the target classes.  For example, 'c-15' --> 0, 'c-16' --> 1, and so on.\n",
    "- It depends on how you write the code, but you can separate the 'target' y column from the x part (216 features).  If you do, you may want to reshape the new integer-target column (to (-1, 1)) to ensure a numpy column vector/array.\n",
    "- Note he original nominal/string target column won't be needed after integer conversion -- you only use the converted column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e04ce064",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T23:47:48.841574Z",
     "iopub.status.busy": "2023-11-21T23:47:48.841263Z",
     "iopub.status.idle": "2023-11-21T23:47:48.868619Z",
     "shell.execute_reply": "2023-11-21T23:47:48.867883Z"
    },
    "papermill": {
     "duration": 0.033915,
     "end_time": "2023-11-21T23:47:48.870337",
     "exception": false,
     "start_time": "2023-11-21T23:47:48.836422",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f-1-1</th>\n",
       "      <th>f-1-2</th>\n",
       "      <th>f-1-3</th>\n",
       "      <th>f-1-4</th>\n",
       "      <th>f-1-5</th>\n",
       "      <th>f-1-6</th>\n",
       "      <th>f-1-7</th>\n",
       "      <th>f-1-8</th>\n",
       "      <th>f-1-9</th>\n",
       "      <th>f-1-10</th>\n",
       "      <th>...</th>\n",
       "      <th>f-6-27</th>\n",
       "      <th>f-6-28</th>\n",
       "      <th>f-6-29</th>\n",
       "      <th>f-6-30</th>\n",
       "      <th>f-6-31</th>\n",
       "      <th>f-6-32</th>\n",
       "      <th>f-6-33</th>\n",
       "      <th>f-6-34</th>\n",
       "      <th>f-6-35</th>\n",
       "      <th>f-6-36</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25.575000</td>\n",
       "      <td>25.5650</td>\n",
       "      <td>6.8052</td>\n",
       "      <td>-26.012</td>\n",
       "      <td>-55.1290</td>\n",
       "      <td>-62.0750</td>\n",
       "      <td>-43.3400</td>\n",
       "      <td>-14.26500</td>\n",
       "      <td>4.03600</td>\n",
       "      <td>2.8128</td>\n",
       "      <td>...</td>\n",
       "      <td>114.9600</td>\n",
       "      <td>116.3700</td>\n",
       "      <td>69.0540</td>\n",
       "      <td>11.8250</td>\n",
       "      <td>29.5960</td>\n",
       "      <td>55.14500</td>\n",
       "      <td>1.0701</td>\n",
       "      <td>-31.4420</td>\n",
       "      <td>20.914</td>\n",
       "      <td>39.9590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.432400</td>\n",
       "      <td>10.4920</td>\n",
       "      <td>16.6900</td>\n",
       "      <td>14.609</td>\n",
       "      <td>3.8112</td>\n",
       "      <td>-8.9224</td>\n",
       "      <td>-15.1370</td>\n",
       "      <td>-11.82400</td>\n",
       "      <td>-3.60240</td>\n",
       "      <td>2.0792</td>\n",
       "      <td>...</td>\n",
       "      <td>16.7950</td>\n",
       "      <td>3.3646</td>\n",
       "      <td>5.7902</td>\n",
       "      <td>52.7540</td>\n",
       "      <td>-19.5210</td>\n",
       "      <td>-9.35210</td>\n",
       "      <td>63.4920</td>\n",
       "      <td>-17.8800</td>\n",
       "      <td>-40.938</td>\n",
       "      <td>6.2865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.166710</td>\n",
       "      <td>-1.0756</td>\n",
       "      <td>-0.8531</td>\n",
       "      <td>1.626</td>\n",
       "      <td>-1.8959</td>\n",
       "      <td>2.4717</td>\n",
       "      <td>-0.2629</td>\n",
       "      <td>-1.43750</td>\n",
       "      <td>0.89766</td>\n",
       "      <td>-2.4570</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.3971</td>\n",
       "      <td>-8.2973</td>\n",
       "      <td>8.8071</td>\n",
       "      <td>-3.6586</td>\n",
       "      <td>-6.4716</td>\n",
       "      <td>0.87079</td>\n",
       "      <td>2.6530</td>\n",
       "      <td>2.2138</td>\n",
       "      <td>-1.323</td>\n",
       "      <td>-2.1806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-4.800300</td>\n",
       "      <td>-3.5558</td>\n",
       "      <td>-5.2497</td>\n",
       "      <td>-10.011</td>\n",
       "      <td>-10.9800</td>\n",
       "      <td>-3.5785</td>\n",
       "      <td>4.9622</td>\n",
       "      <td>2.28200</td>\n",
       "      <td>-11.07200</td>\n",
       "      <td>-17.1180</td>\n",
       "      <td>...</td>\n",
       "      <td>2.9662</td>\n",
       "      <td>-6.1161</td>\n",
       "      <td>-34.6170</td>\n",
       "      <td>-96.5080</td>\n",
       "      <td>-94.9050</td>\n",
       "      <td>-8.84960</td>\n",
       "      <td>48.7190</td>\n",
       "      <td>-15.2810</td>\n",
       "      <td>-15.786</td>\n",
       "      <td>34.8360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.048579</td>\n",
       "      <td>-11.9320</td>\n",
       "      <td>-25.6890</td>\n",
       "      <td>-35.259</td>\n",
       "      <td>-36.0600</td>\n",
       "      <td>-27.6460</td>\n",
       "      <td>-13.9240</td>\n",
       "      <td>-0.79703</td>\n",
       "      <td>7.31190</td>\n",
       "      <td>9.8219</td>\n",
       "      <td>...</td>\n",
       "      <td>63.1690</td>\n",
       "      <td>64.7760</td>\n",
       "      <td>53.0120</td>\n",
       "      <td>-83.1160</td>\n",
       "      <td>-50.6480</td>\n",
       "      <td>79.74300</td>\n",
       "      <td>-16.5700</td>\n",
       "      <td>74.2040</td>\n",
       "      <td>72.036</td>\n",
       "      <td>100.2200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 216 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       f-1-1    f-1-2    f-1-3   f-1-4    f-1-5    f-1-6    f-1-7     f-1-8  \\\n",
       "0  25.575000  25.5650   6.8052 -26.012 -55.1290 -62.0750 -43.3400 -14.26500   \n",
       "1   2.432400  10.4920  16.6900  14.609   3.8112  -8.9224 -15.1370 -11.82400   \n",
       "2  -0.166710  -1.0756  -0.8531   1.626  -1.8959   2.4717  -0.2629  -1.43750   \n",
       "3  -4.800300  -3.5558  -5.2497 -10.011 -10.9800  -3.5785   4.9622   2.28200   \n",
       "4  -0.048579 -11.9320 -25.6890 -35.259 -36.0600 -27.6460 -13.9240  -0.79703   \n",
       "\n",
       "      f-1-9   f-1-10  ...    f-6-27    f-6-28   f-6-29   f-6-30   f-6-31  \\\n",
       "0   4.03600   2.8128  ...  114.9600  116.3700  69.0540  11.8250  29.5960   \n",
       "1  -3.60240   2.0792  ...   16.7950    3.3646   5.7902  52.7540 -19.5210   \n",
       "2   0.89766  -2.4570  ...   -3.3971   -8.2973   8.8071  -3.6586  -6.4716   \n",
       "3 -11.07200 -17.1180  ...    2.9662   -6.1161 -34.6170 -96.5080 -94.9050   \n",
       "4   7.31190   9.8219  ...   63.1690   64.7760  53.0120 -83.1160 -50.6480   \n",
       "\n",
       "     f-6-32   f-6-33   f-6-34  f-6-35    f-6-36  \n",
       "0  55.14500   1.0701 -31.4420  20.914   39.9590  \n",
       "1  -9.35210  63.4920 -17.8800 -40.938    6.2865  \n",
       "2   0.87079   2.6530   2.2138  -1.323   -2.1806  \n",
       "3  -8.84960  48.7190 -15.2810 -15.786   34.8360  \n",
       "4  79.74300 -16.5700  74.2040  72.036  100.2200  \n",
       "\n",
       "[5 rows x 216 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parent_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84e5569f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T23:47:48.879123Z",
     "iopub.status.busy": "2023-11-21T23:47:48.878867Z",
     "iopub.status.idle": "2023-11-21T23:47:48.902854Z",
     "shell.execute_reply": "2023-11-21T23:47:48.902172Z"
    },
    "papermill": {
     "duration": 0.03026,
     "end_time": "2023-11-21T23:47:48.904511",
     "exception": false,
     "start_time": "2023-11-21T23:47:48.874251",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f-1-1</th>\n",
       "      <th>f-1-2</th>\n",
       "      <th>f-1-3</th>\n",
       "      <th>f-1-4</th>\n",
       "      <th>f-1-5</th>\n",
       "      <th>f-1-6</th>\n",
       "      <th>f-1-7</th>\n",
       "      <th>f-1-8</th>\n",
       "      <th>f-1-9</th>\n",
       "      <th>f-1-10</th>\n",
       "      <th>...</th>\n",
       "      <th>f-6-27</th>\n",
       "      <th>f-6-28</th>\n",
       "      <th>f-6-29</th>\n",
       "      <th>f-6-30</th>\n",
       "      <th>f-6-31</th>\n",
       "      <th>f-6-32</th>\n",
       "      <th>f-6-33</th>\n",
       "      <th>f-6-34</th>\n",
       "      <th>f-6-35</th>\n",
       "      <th>f-6-36</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.57770</td>\n",
       "      <td>-1.18830</td>\n",
       "      <td>-4.98950</td>\n",
       "      <td>-6.4301</td>\n",
       "      <td>-4.6503</td>\n",
       "      <td>-1.02450</td>\n",
       "      <td>1.90420</td>\n",
       "      <td>2.48850</td>\n",
       "      <td>1.360500</td>\n",
       "      <td>0.90286</td>\n",
       "      <td>...</td>\n",
       "      <td>13.5590</td>\n",
       "      <td>22.36600</td>\n",
       "      <td>-24.7480</td>\n",
       "      <td>-34.21500</td>\n",
       "      <td>7.7464</td>\n",
       "      <td>-5.8332</td>\n",
       "      <td>-0.71757</td>\n",
       "      <td>8.16160</td>\n",
       "      <td>-29.6940</td>\n",
       "      <td>-27.5700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.67580</td>\n",
       "      <td>22.54300</td>\n",
       "      <td>44.02700</td>\n",
       "      <td>66.9610</td>\n",
       "      <td>86.0820</td>\n",
       "      <td>96.80400</td>\n",
       "      <td>96.76000</td>\n",
       "      <td>86.49400</td>\n",
       "      <td>69.094000</td>\n",
       "      <td>48.97100</td>\n",
       "      <td>...</td>\n",
       "      <td>-22.6270</td>\n",
       "      <td>19.26700</td>\n",
       "      <td>28.5110</td>\n",
       "      <td>0.97578</td>\n",
       "      <td>-28.0270</td>\n",
       "      <td>-18.0720</td>\n",
       "      <td>-4.00020</td>\n",
       "      <td>-43.07500</td>\n",
       "      <td>-4.7283</td>\n",
       "      <td>-43.0070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.37554</td>\n",
       "      <td>-3.10860</td>\n",
       "      <td>-0.26009</td>\n",
       "      <td>3.2281</td>\n",
       "      <td>-1.9951</td>\n",
       "      <td>0.12797</td>\n",
       "      <td>0.25844</td>\n",
       "      <td>-0.25394</td>\n",
       "      <td>-0.091828</td>\n",
       "      <td>2.41440</td>\n",
       "      <td>...</td>\n",
       "      <td>2.3504</td>\n",
       "      <td>-4.02610</td>\n",
       "      <td>14.5270</td>\n",
       "      <td>50.00500</td>\n",
       "      <td>-13.8860</td>\n",
       "      <td>3.3589</td>\n",
       "      <td>5.00450</td>\n",
       "      <td>-0.47256</td>\n",
       "      <td>-2.7713</td>\n",
       "      <td>1.9379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.51852</td>\n",
       "      <td>0.12078</td>\n",
       "      <td>1.53240</td>\n",
       "      <td>5.5783</td>\n",
       "      <td>11.5340</td>\n",
       "      <td>17.01300</td>\n",
       "      <td>18.97100</td>\n",
       "      <td>15.38700</td>\n",
       "      <td>6.685500</td>\n",
       "      <td>-4.07800</td>\n",
       "      <td>...</td>\n",
       "      <td>17.4670</td>\n",
       "      <td>23.24700</td>\n",
       "      <td>31.9850</td>\n",
       "      <td>26.62100</td>\n",
       "      <td>-12.2560</td>\n",
       "      <td>3.4805</td>\n",
       "      <td>23.80500</td>\n",
       "      <td>-32.36400</td>\n",
       "      <td>-15.1610</td>\n",
       "      <td>-14.4500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.47150</td>\n",
       "      <td>1.44510</td>\n",
       "      <td>2.91330</td>\n",
       "      <td>1.0015</td>\n",
       "      <td>-1.2503</td>\n",
       "      <td>1.55160</td>\n",
       "      <td>1.73170</td>\n",
       "      <td>0.47796</td>\n",
       "      <td>0.539860</td>\n",
       "      <td>-1.71690</td>\n",
       "      <td>...</td>\n",
       "      <td>2.1311</td>\n",
       "      <td>-0.18477</td>\n",
       "      <td>3.8533</td>\n",
       "      <td>-5.80000</td>\n",
       "      <td>1.4909</td>\n",
       "      <td>2.7581</td>\n",
       "      <td>-3.16650</td>\n",
       "      <td>-0.30058</td>\n",
       "      <td>6.6334</td>\n",
       "      <td>7.3427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 216 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     f-1-1     f-1-2     f-1-3    f-1-4    f-1-5     f-1-6     f-1-7  \\\n",
       "0  2.57770  -1.18830  -4.98950  -6.4301  -4.6503  -1.02450   1.90420   \n",
       "1  6.67580  22.54300  44.02700  66.9610  86.0820  96.80400  96.76000   \n",
       "2  0.37554  -3.10860  -0.26009   3.2281  -1.9951   0.12797   0.25844   \n",
       "3  0.51852   0.12078   1.53240   5.5783  11.5340  17.01300  18.97100   \n",
       "4  1.47150   1.44510   2.91330   1.0015  -1.2503   1.55160   1.73170   \n",
       "\n",
       "      f-1-8      f-1-9    f-1-10  ...   f-6-27    f-6-28   f-6-29    f-6-30  \\\n",
       "0   2.48850   1.360500   0.90286  ...  13.5590  22.36600 -24.7480 -34.21500   \n",
       "1  86.49400  69.094000  48.97100  ... -22.6270  19.26700  28.5110   0.97578   \n",
       "2  -0.25394  -0.091828   2.41440  ...   2.3504  -4.02610  14.5270  50.00500   \n",
       "3  15.38700   6.685500  -4.07800  ...  17.4670  23.24700  31.9850  26.62100   \n",
       "4   0.47796   0.539860  -1.71690  ...   2.1311  -0.18477   3.8533  -5.80000   \n",
       "\n",
       "    f-6-31   f-6-32    f-6-33    f-6-34   f-6-35   f-6-36  \n",
       "0   7.7464  -5.8332  -0.71757   8.16160 -29.6940 -27.5700  \n",
       "1 -28.0270 -18.0720  -4.00020 -43.07500  -4.7283 -43.0070  \n",
       "2 -13.8860   3.3589   5.00450  -0.47256  -2.7713   1.9379  \n",
       "3 -12.2560   3.4805  23.80500 -32.36400 -15.1610 -14.4500  \n",
       "4   1.4909   2.7581  -3.16650  -0.30058   6.6334   7.3427  \n",
       "\n",
       "[5 rows x 216 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = parent_train['target'].values\n",
    "parent_train = parent_train.drop('target', axis=1)\n",
    "parent_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27ccd1d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T23:47:48.914412Z",
     "iopub.status.busy": "2023-11-21T23:47:48.914182Z",
     "iopub.status.idle": "2023-11-21T23:47:48.920123Z",
     "shell.execute_reply": "2023-11-21T23:47:48.919462Z"
    },
    "papermill": {
     "duration": 0.012834,
     "end_time": "2023-11-21T23:47:48.921768",
     "exception": false,
     "start_time": "2023-11-21T23:47:48.908934",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3356, 1)\n"
     ]
    }
   ],
   "source": [
    "classes = np.unique(y) \n",
    "class_to_idx = {c: i for i, c in enumerate(classes)}\n",
    "y_int = np.array([class_to_idx[c] for c in y]) \n",
    "y_int = y_int.reshape(-1,1)\n",
    "print(y_int.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12d441d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T23:47:48.931997Z",
     "iopub.status.busy": "2023-11-21T23:47:48.931765Z",
     "iopub.status.idle": "2023-11-21T23:47:48.938078Z",
     "shell.execute_reply": "2023-11-21T23:47:48.937466Z"
    },
    "papermill": {
     "duration": 0.013715,
     "end_time": "2023-11-21T23:47:48.939947",
     "exception": false,
     "start_time": "2023-11-21T23:47:48.926232",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "[[8]\n",
      " [0]\n",
      " [2]\n",
      " ...\n",
      " [4]\n",
      " [2]\n",
      " [8]]\n"
     ]
    }
   ],
   "source": [
    "classes_ = np.unique(y) \n",
    "print(len(classes_))\n",
    "class_to_idx = {c: i for i, c in enumerate(classes_)}\n",
    "y_int = np.array([class_to_idx[c] for c in y]) \n",
    "y_int = y_int.reshape(-1,1)\n",
    "print(y_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e94404b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T23:47:48.949092Z",
     "iopub.status.busy": "2023-11-21T23:47:48.948847Z",
     "iopub.status.idle": "2023-11-21T23:47:48.952996Z",
     "shell.execute_reply": "2023-11-21T23:47:48.952417Z"
    },
    "papermill": {
     "duration": 0.010625,
     "end_time": "2023-11-21T23:47:48.954599",
     "exception": false,
     "start_time": "2023-11-21T23:47:48.943974",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3356, 6, 36)\n"
     ]
    }
   ],
   "source": [
    "timesteps = 6\n",
    "features_per_timestep = 36\n",
    "X_train = parent_train.values.reshape(-1, timesteps, features_per_timestep)\n",
    "input_shape = X_train.shape[1:]\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8761a1ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T23:47:48.964878Z",
     "iopub.status.busy": "2023-11-21T23:47:48.964650Z",
     "iopub.status.idle": "2023-11-21T23:47:48.968423Z",
     "shell.execute_reply": "2023-11-21T23:47:48.967829Z"
    },
    "papermill": {
     "duration": 0.010851,
     "end_time": "2023-11-21T23:47:48.970137",
     "exception": false,
     "start_time": "2023-11-21T23:47:48.959286",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1439, 6, 36)\n"
     ]
    }
   ],
   "source": [
    "timesteps = 6\n",
    "features_per_timestep = 36\n",
    "Ytest = parent_test.values.reshape(-1, timesteps, features_per_timestep)\n",
    "print(Ytest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1adf91a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T23:47:48.982826Z",
     "iopub.status.busy": "2023-11-21T23:47:48.982364Z",
     "iopub.status.idle": "2023-11-21T23:47:50.914186Z",
     "shell.execute_reply": "2023-11-21T23:47:50.913490Z"
    },
    "papermill": {
     "duration": 1.939988,
     "end_time": "2023-11-21T23:47:50.916545",
     "exception": false,
     "start_time": "2023-11-21T23:47:48.976557",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "X_train_, X_val, y_train_, y_val = train_test_split( X_train, y_int, test_size=0.2, random_state=42) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9e7ca1",
   "metadata": {
    "papermill": {
     "duration": 0.004289,
     "end_time": "2023-11-21T23:47:50.925596",
     "exception": false,
     "start_time": "2023-11-21T23:47:50.921307",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Error Analysis for the model to check the Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56433994",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T23:47:50.935549Z",
     "iopub.status.busy": "2023-11-21T23:47:50.935192Z",
     "iopub.status.idle": "2023-11-21T23:47:50.940277Z",
     "shell.execute_reply": "2023-11-21T23:47:50.939596Z"
    },
    "papermill": {
     "duration": 0.012091,
     "end_time": "2023-11-21T23:47:50.941869",
     "exception": false,
     "start_time": "2023-11-21T23:47:50.929778",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, fbeta_score\n",
    "def error_analysis(model, X_val, y_val):\n",
    "    y_pred = model.predict(X_val)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    # Calculate Precision, Recall, and F2-score\n",
    "    precision = precision_score(y_val, y_pred_classes, average='weighted')\n",
    "    recall = recall_score(y_val, y_pred_classes, average='weighted')\n",
    "    f2_score = fbeta_score(y_val, y_pred_classes, beta=2, average='weighted')\n",
    "\n",
    "    # Print error analysis metrics\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F2 Score: {f2_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf529c89",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T23:47:50.951578Z",
     "iopub.status.busy": "2023-11-21T23:47:50.951333Z",
     "iopub.status.idle": "2023-11-21T23:48:04.852274Z",
     "shell.execute_reply": "2023-11-21T23:48:04.851374Z"
    },
    "papermill": {
     "duration": 13.908799,
     "end_time": "2023-11-21T23:48:04.854652",
     "exception": false,
     "start_time": "2023-11-21T23:47:50.945853",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.regularizers import l1, l2\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "classes = len(classes_) \n",
    "def model2():\n",
    "    input_shape = X_train.shape[1:] \n",
    "    normalizer = tf.keras.layers.Normalization() \n",
    "    normalizer.adapt(X_train)\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    x = normalizer(inputs)\n",
    "    #x = tf.keras.layers.LSTM(8)(x)\n",
    "    #x = tf.keras.layers.GRU(8,activation=\"relu\", dropout=0.5,)(x)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
    "    x  = tf.keras.layers.Dropout(0.2)(x)\n",
    "    x = tf.keras.layers.Dense(64, activation='softmax')(x)\n",
    "    outputs = tf.keras.layers.Dense(classes, activation='softmax')(x) \n",
    "    lstm_model = keras.Model(inputs, outputs)\n",
    "    lstm_model.compile(optimizer='adam',\n",
    "                   loss='sparse_categorical_crossentropy', \n",
    "                   metrics=['accuracy'])\n",
    "    lstm_model.summary()\n",
    "    return lstm_model \n",
    "\n",
    "def model3():\n",
    "    input_shape = X_train.shape[1:] \n",
    "    normalizer = tf.keras.layers.Normalization() \n",
    "    normalizer.adapt(X_train)\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    x = normalizer(inputs)\n",
    "    #x = tf.keras.layers.LSTM(8)(x)\n",
    "    #x = tf.keras.layers.GRU(8,activation=\"relu\", dropout=0.5,)(x)\n",
    "    x = tf.keras.layers.SimpleRNN(\n",
    "    32,\n",
    "    activation=\"tanh\",\n",
    "    use_bias=True,\n",
    "    kernel_initializer=\"glorot_uniform\",\n",
    "    recurrent_initializer=\"orthogonal\",\n",
    "    bias_initializer=\"zeros\",\n",
    "    kernel_regularizer=l1(0.01),\n",
    "    recurrent_regularizer=None,\n",
    "    bias_regularizer=None,\n",
    "    )(x)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    \"\"\"\n",
    "    x = tf.keras.layers.Dense(64, activation='softmax')(x)\n",
    "    x  = tf.keras.layers.Dropout(0.2)(x)\"\"\"\n",
    "    outputs = tf.keras.layers.Dense(classes, activation='softmax')(x) \n",
    "    lstm_model = keras.Model(inputs, outputs)\n",
    "    # Define a custom learning rate\n",
    "    custom_lr = 0.001\n",
    "\n",
    "    # Create an Adam optimizer with the specified learning rate\n",
    "    optimizer = Adam(learning_rate=custom_lr)\n",
    "    lstm_model.compile(optimizer=optimizer,\n",
    "                   loss='sparse_categorical_crossentropy', \n",
    "                   metrics=['accuracy'])\n",
    "    lstm_model.summary()\n",
    "    return lstm_model \n",
    "def model4():\n",
    "    from tensorflow.keras.models import Model\n",
    "    from tensorflow.keras import layers\n",
    "    # Assuming 'X_train' and 'num_classes' are defined elsewhere\n",
    "    input_shape = X_train.shape[1:] \n",
    "    normalizer = tf.keras.layers.Normalization() \n",
    "    normalizer.adapt(X_train)\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    x = normalizer(inputs)\n",
    "    x = layers.Conv1D(filters=64, kernel_size=5, activation='relu',kernel_regularizer=l1(0.01))(x)\n",
    "    out = layers.Dense(classes, activation='softmax')(x)\n",
    "    # Define the model\n",
    "    model = Model(inputs, out)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(lr=0.001),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy'],callbacks=[early_stopping]\n",
    "    )\n",
    "\n",
    "    return model\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, BatchNormalization, Dense, Dropout\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import LSTM, BatchNormalization, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "def model_with_dropout():####as of now this is the best model.\n",
    "    input_shape = X_train.shape[1:] \n",
    "    normalizer = tf.keras.layers.Normalization() \n",
    "    normalizer.adapt(X_train)\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    x = normalizer(inputs)\n",
    "    x = LSTM(128, activation='relu', dropout=0.3, recurrent_dropout=0.3)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    # Additional Dense layers (you can uncomment and adjust as needed)\n",
    "    \"\"\"\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    \"\"\"\n",
    "    # Dense layers for classification with dropout\n",
    "    x = Dense(256, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    out = Dense(classes, activation='softmax')(x)\n",
    "    # Define the model\n",
    "    model = Model(inputs, out)\n",
    "    # Compile the model\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)  # Define the optimizer with learning_rate\n",
    "    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "def multi_model():####as of now this is the best model.\n",
    "    input_shape = X_train.shape[1:] \n",
    "    normalizer = tf.keras.layers.Normalization() \n",
    "    normalizer.adapt(X_train)\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    x = normalizer(inputs)\n",
    "    rnn = layers.Bidirectional(layers.SimpleRNN(64, return_sequences=True, kernel_regularizer=l1(0.01)))(inputs)  \n",
    "\n",
    "    # 1D Conv Layer \n",
    "    conv = layers.Conv1D(filters=32, kernel_size=3, activation='relu',kernel_regularizer=l2(0.01))(rnn)\n",
    "\n",
    "    # ConvLSTM Layer\n",
    "    #conv_lstm = layers.ConvLSTM2D(filters=64, kernel_size=(1, 3))(conv) \n",
    "\n",
    "    # MLP Classifier  \n",
    "    x = layers.GlobalAveragePooling1D()(conv)\n",
    "    x = layers.Dropout(0.5)(x)  \n",
    "    outputs = layers.Dense(classes, activation='softmax')(x)\n",
    "    x = Dense(256, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    out = Dense(classes, activation='softmax')(x)\n",
    "    # Define the model\n",
    "    model = Model(inputs, out)\n",
    "    # Compile the model\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)  # Define the optimizer with learning_rate\n",
    "    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47931978",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T23:48:04.865914Z",
     "iopub.status.busy": "2023-11-21T23:48:04.865392Z",
     "iopub.status.idle": "2023-11-21T23:48:28.881672Z",
     "shell.execute_reply": "2023-11-21T23:48:28.880533Z"
    },
    "papermill": {
     "duration": 24.023888,
     "end_time": "2023-11-21T23:48:28.883453",
     "exception": false,
     "start_time": "2023-11-21T23:48:04.859565",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-21 23:48:07.966066: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n",
      "2023-11-21 23:48:07.966188: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n",
      "2023-11-21 23:48:07.966279: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n",
      "2023-11-21 23:48:07.966353: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n",
      "2023-11-21 23:48:07.966421: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n",
      "2023-11-21 23:48:07.966650: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n",
      "2023-11-21 23:48:07.966770: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n",
      "2023-11-21 23:48:07.966868: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n",
      "2023-11-21 23:48:07.966951: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n",
      "2023-11-21 23:48:07.967039: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n",
      "2023-11-21 23:48:07.967261: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n",
      "2023-11-21 23:48:07.967356: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n",
      "2023-11-21 23:48:07.967442: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n",
      "2023-11-21 23:48:07.967537: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n",
      "2023-11-21 23:48:07.967620: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n",
      "2023-11-21 23:48:07.967818: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n",
      "2023-11-21 23:48:07.967905: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n",
      "2023-11-21 23:48:07.967990: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n",
      "2023-11-21 23:48:07.968078: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n",
      "2023-11-21 23:48:07.968165: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n",
      "2023-11-21 23:48:07.968377: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n",
      "2023-11-21 23:48:07.968462: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n",
      "2023-11-21 23:48:07.968613: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n",
      "2023-11-21 23:48:07.968698: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n",
      "2023-11-21 23:48:07.968780: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n",
      "2023-11-21 23:48:07.969003: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n",
      "2023-11-21 23:48:07.969089: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n",
      "2023-11-21 23:48:07.969172: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n",
      "2023-11-21 23:48:07.969254: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n",
      "2023-11-21 23:48:07.969331: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n",
      "2023-11-21 23:48:07.969616: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n",
      "2023-11-21 23:48:07.969706: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n",
      "2023-11-21 23:48:07.969794: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n",
      "2023-11-21 23:48:07.969925: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n",
      "2023-11-21 23:48:07.970050: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n",
      "2023-11-21 23:48:07.970347: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n",
      "2023-11-21 23:48:07.970494: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n",
      "2023-11-21 23:48:07.970591: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n",
      "2023-11-21 23:48:07.970675: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n",
      "2023-11-21 23:48:07.970769: E ./tensorflow/compiler/xla/stream_executor/stream_executor_internal.h:124] SetPriority unimplemented for this stream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 6, 36)]           0         \n",
      "                                                                 \n",
      " normalization (Normalizati  (None, 6, 36)             73        \n",
      " on)                                                             \n",
      "                                                                 \n",
      " simple_rnn (SimpleRNN)      (None, 32)                2208      \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 11)                363       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2644 (10.33 KB)\n",
      "Trainable params: 2571 (10.04 KB)\n",
      "Non-trainable params: 73 (296.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/120\n",
      "84/84 [==============================] - 2s 8ms/step - loss: 3.5336 - accuracy: 0.3018 - val_loss: 3.1012 - val_accuracy: 0.3616\n",
      "Epoch 2/120\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 2.8676 - accuracy: 0.3245 - val_loss: 2.6314 - val_accuracy: 0.3616\n",
      "Epoch 3/120\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 2.4739 - accuracy: 0.3420 - val_loss: 2.2923 - val_accuracy: 0.3765\n",
      "Epoch 4/120\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 2.2154 - accuracy: 0.3547 - val_loss: 2.0911 - val_accuracy: 0.3958\n",
      "Epoch 5/120\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 2.0738 - accuracy: 0.3655 - val_loss: 1.9962 - val_accuracy: 0.3958\n",
      "Epoch 6/120\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1.9972 - accuracy: 0.3696 - val_loss: 1.9450 - val_accuracy: 0.4048\n",
      "Epoch 7/120\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1.9462 - accuracy: 0.3767 - val_loss: 1.9176 - val_accuracy: 0.4033\n",
      "Epoch 8/120\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1.9187 - accuracy: 0.3804 - val_loss: 1.8866 - val_accuracy: 0.4062\n",
      "Epoch 9/120\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1.8873 - accuracy: 0.3893 - val_loss: 1.8773 - val_accuracy: 0.4137\n",
      "Epoch 10/120\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1.8643 - accuracy: 0.3920 - val_loss: 1.8564 - val_accuracy: 0.4211\n",
      "Epoch 11/120\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1.8388 - accuracy: 0.3968 - val_loss: 1.8452 - val_accuracy: 0.4152\n",
      "Epoch 12/120\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1.8234 - accuracy: 0.3946 - val_loss: 1.8390 - val_accuracy: 0.4182\n",
      "Epoch 13/120\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1.8175 - accuracy: 0.4054 - val_loss: 1.8264 - val_accuracy: 0.4256\n",
      "Epoch 14/120\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1.7935 - accuracy: 0.4069 - val_loss: 1.8351 - val_accuracy: 0.4137\n",
      "Epoch 15/120\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1.7894 - accuracy: 0.4072 - val_loss: 1.8013 - val_accuracy: 0.4182\n",
      "Epoch 16/120\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1.7692 - accuracy: 0.4117 - val_loss: 1.7991 - val_accuracy: 0.4315\n",
      "Epoch 17/120\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1.7693 - accuracy: 0.4151 - val_loss: 1.8034 - val_accuracy: 0.4405\n",
      "Epoch 18/120\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1.7651 - accuracy: 0.4173 - val_loss: 1.7904 - val_accuracy: 0.4405\n",
      "Epoch 19/120\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1.7467 - accuracy: 0.4147 - val_loss: 1.7646 - val_accuracy: 0.4301\n",
      "Epoch 20/120\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1.7355 - accuracy: 0.4195 - val_loss: 1.7521 - val_accuracy: 0.4375\n",
      "Epoch 21/120\n",
      "84/84 [==============================] - 0s 4ms/step - loss: 1.7293 - accuracy: 0.4270 - val_loss: 1.7613 - val_accuracy: 0.4315\n",
      "Epoch 22/120\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1.7499 - accuracy: 0.4206 - val_loss: 1.7858 - val_accuracy: 0.4375\n",
      "Epoch 23/120\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1.7167 - accuracy: 0.4285 - val_loss: 1.7424 - val_accuracy: 0.4435\n",
      "Epoch 24/120\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1.7180 - accuracy: 0.4285 - val_loss: 1.8166 - val_accuracy: 0.4301\n",
      "Epoch 25/120\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1.7257 - accuracy: 0.4326 - val_loss: 1.7542 - val_accuracy: 0.4494\n",
      "Epoch 26/120\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1.7094 - accuracy: 0.4303 - val_loss: 1.7475 - val_accuracy: 0.4420\n",
      "Epoch 27/120\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1.7049 - accuracy: 0.4307 - val_loss: 1.7201 - val_accuracy: 0.4479\n",
      "Epoch 28/120\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1.6890 - accuracy: 0.4385 - val_loss: 1.7411 - val_accuracy: 0.4420\n",
      "Epoch 29/120\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1.6770 - accuracy: 0.4396 - val_loss: 1.7513 - val_accuracy: 0.4613\n",
      "Epoch 30/120\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1.6880 - accuracy: 0.4404 - val_loss: 1.7288 - val_accuracy: 0.4449\n",
      "Epoch 31/120\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1.6962 - accuracy: 0.4370 - val_loss: 1.7553 - val_accuracy: 0.4405\n",
      "Epoch 32/120\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1.6639 - accuracy: 0.4419 - val_loss: 1.7186 - val_accuracy: 0.4509\n",
      "Epoch 33/120\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1.6619 - accuracy: 0.4523 - val_loss: 1.7119 - val_accuracy: 0.4464\n",
      "Epoch 34/120\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1.6735 - accuracy: 0.4452 - val_loss: 1.7148 - val_accuracy: 0.4568\n",
      "Epoch 35/120\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1.6609 - accuracy: 0.4557 - val_loss: 1.7280 - val_accuracy: 0.4449\n",
      "Epoch 36/120\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1.6527 - accuracy: 0.4512 - val_loss: 1.7166 - val_accuracy: 0.4449\n",
      "Epoch 37/120\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1.6373 - accuracy: 0.4560 - val_loss: 1.6853 - val_accuracy: 0.4598\n",
      "Epoch 38/120\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1.6618 - accuracy: 0.4501 - val_loss: 1.7222 - val_accuracy: 0.4583\n",
      "Epoch 39/120\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1.6526 - accuracy: 0.4624 - val_loss: 1.6913 - val_accuracy: 0.4628\n",
      "Epoch 40/120\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1.6397 - accuracy: 0.4635 - val_loss: 1.6841 - val_accuracy: 0.4628\n",
      "Epoch 41/120\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1.6192 - accuracy: 0.4665 - val_loss: 1.6783 - val_accuracy: 0.4568\n",
      "Epoch 42/120\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1.6084 - accuracy: 0.4668 - val_loss: 1.6674 - val_accuracy: 0.4688\n",
      "Epoch 43/120\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1.6023 - accuracy: 0.4769 - val_loss: 1.6832 - val_accuracy: 0.4554\n",
      "Epoch 44/120\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1.6268 - accuracy: 0.4676 - val_loss: 1.6849 - val_accuracy: 0.4613\n",
      "Epoch 45/120\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1.6118 - accuracy: 0.4773 - val_loss: 1.6839 - val_accuracy: 0.4792\n",
      "Epoch 46/120\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1.5902 - accuracy: 0.4776 - val_loss: 1.7117 - val_accuracy: 0.4449\n",
      "Epoch 47/120\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1.5928 - accuracy: 0.4780 - val_loss: 1.6747 - val_accuracy: 0.4940\n",
      "Epoch 48/120\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1.5846 - accuracy: 0.4877 - val_loss: 1.6580 - val_accuracy: 0.4881\n",
      "Epoch 49/120\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1.5795 - accuracy: 0.4765 - val_loss: 1.6616 - val_accuracy: 0.4717\n",
      "Epoch 50/120\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1.5787 - accuracy: 0.4773 - val_loss: 1.7396 - val_accuracy: 0.4241\n",
      "Epoch 51/120\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1.6083 - accuracy: 0.4840 - val_loss: 1.6665 - val_accuracy: 0.4940\n",
      "Epoch 52/120\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1.6098 - accuracy: 0.4750 - val_loss: 1.6490 - val_accuracy: 0.4777\n",
      "Epoch 53/120\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1.5785 - accuracy: 0.4844 - val_loss: 1.6584 - val_accuracy: 0.4866\n",
      "Epoch 54/120\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1.5714 - accuracy: 0.4873 - val_loss: 1.6729 - val_accuracy: 0.4940\n",
      "Epoch 55/120\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1.5827 - accuracy: 0.4885 - val_loss: 1.6579 - val_accuracy: 0.4777\n",
      "Epoch 56/120\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1.5818 - accuracy: 0.4851 - val_loss: 1.6441 - val_accuracy: 0.4762\n",
      "Epoch 57/120\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1.5499 - accuracy: 0.4888 - val_loss: 1.6827 - val_accuracy: 0.4717\n",
      "Epoch 58/120\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1.5825 - accuracy: 0.4821 - val_loss: 1.6647 - val_accuracy: 0.4762\n",
      "Epoch 59/120\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1.5551 - accuracy: 0.4959 - val_loss: 1.6423 - val_accuracy: 0.4970\n",
      "Epoch 60/120\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1.5648 - accuracy: 0.4829 - val_loss: 1.6452 - val_accuracy: 0.4821\n",
      "Epoch 61/120\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1.5536 - accuracy: 0.4832 - val_loss: 1.6496 - val_accuracy: 0.4673\n",
      "Epoch 62/120\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1.5410 - accuracy: 0.4903 - val_loss: 1.6352 - val_accuracy: 0.4881\n",
      "Epoch 63/120\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1.5519 - accuracy: 0.4918 - val_loss: 1.6599 - val_accuracy: 0.4747\n",
      "Epoch 64/120\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1.5747 - accuracy: 0.4881 - val_loss: 1.6597 - val_accuracy: 0.4717\n",
      "Epoch 65/120\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1.5538 - accuracy: 0.4892 - val_loss: 1.6423 - val_accuracy: 0.4851\n",
      "Epoch 66/120\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1.5427 - accuracy: 0.4978 - val_loss: 1.6727 - val_accuracy: 0.4896\n",
      "Epoch 67/120\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1.5602 - accuracy: 0.4899 - val_loss: 1.6389 - val_accuracy: 0.4821\n",
      "Epoch 68/120\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1.5468 - accuracy: 0.4989 - val_loss: 1.6703 - val_accuracy: 0.4836\n",
      "Epoch 69/120\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1.5405 - accuracy: 0.4937 - val_loss: 1.6473 - val_accuracy: 0.4807\n",
      "Epoch 70/120\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1.5335 - accuracy: 0.4963 - val_loss: 1.6412 - val_accuracy: 0.4792\n",
      "Epoch 71/120\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1.5769 - accuracy: 0.4989 - val_loss: 1.7230 - val_accuracy: 0.4702\n",
      "Epoch 72/120\n",
      "84/84 [==============================] - 0s 3ms/step - loss: 1.6089 - accuracy: 0.4855 - val_loss: 1.6615 - val_accuracy: 0.4851\n"
     ]
    }
   ],
   "source": [
    "model = model3()\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "history = model.fit(X_train_, y_train_, epochs=120, batch_size=32, validation_data=(X_val, y_val),callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b6255e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T23:48:28.945033Z",
     "iopub.status.busy": "2023-11-21T23:48:28.944234Z",
     "iopub.status.idle": "2023-11-21T23:48:29.238486Z",
     "shell.execute_reply": "2023-11-21T23:48:29.237314Z"
    },
    "papermill": {
     "duration": 0.325967,
     "end_time": "2023-11-21T23:48:29.240210",
     "exception": false,
     "start_time": "2023-11-21T23:48:28.914243",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 2ms/step\n",
      "Precision: 0.4337\n",
      "Recall: 0.4851\n",
      "F2 Score: 0.4493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#Error Analysis\n",
    "error_analysis(model, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eafc48af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T23:48:29.329294Z",
     "iopub.status.busy": "2023-11-21T23:48:29.328912Z",
     "iopub.status.idle": "2023-11-21T23:48:29.565827Z",
     "shell.execute_reply": "2023-11-21T23:48:29.564745Z"
    },
    "papermill": {
     "duration": 0.269715,
     "end_time": "2023-11-21T23:48:29.567795",
     "exception": false,
     "start_time": "2023-11-21T23:48:29.298080",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "#Predicting the model \n",
    "preds = model.predict(Ytest,batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "016de31e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T23:48:29.626832Z",
     "iopub.status.busy": "2023-11-21T23:48:29.626243Z",
     "iopub.status.idle": "2023-11-21T23:48:29.827604Z",
     "shell.execute_reply": "2023-11-21T23:48:29.826790Z"
    },
    "papermill": {
     "duration": 0.232382,
     "end_time": "2023-11-21T23:48:29.829253",
     "exception": false,
     "start_time": "2023-11-21T23:48:29.596871",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 0s 2ms/step\n",
      "        ID      c-15      c-16      c-42      c-52      c-62      c-65  \\\n",
      "ID                                                                       \n",
      "1        0  0.007671  0.014225  0.251205  0.063879  0.091716  0.076363   \n",
      "2        1  0.008125  0.013665  0.224872  0.038708  0.138407  0.065798   \n",
      "3        2  0.030555  0.011976  0.271053  0.040771  0.063353  0.076106   \n",
      "4        3  0.005473  0.016339  0.299360  0.047871  0.146319  0.036423   \n",
      "5        4  0.002148  0.414180  0.000993  0.000449  0.000928  0.151181   \n",
      "...    ...       ...       ...       ...       ...       ...       ...   \n",
      "1435  1434  0.019370  0.149233  0.132818  0.011300  0.032539  0.243381   \n",
      "1436  1435  0.002675  0.736727  0.012920  0.001030  0.005467  0.195414   \n",
      "1437  1436  0.015176  0.010518  0.196329  0.046280  0.067009  0.087222   \n",
      "1438  1437  0.013031  0.015026  0.161225  0.030233  0.088651  0.130902   \n",
      "1439  1438  0.008143  0.005977  0.258396  0.062105  0.114297  0.043067   \n",
      "\n",
      "          c-67      c-88      c-90      c-92      c-95  \n",
      "ID                                                      \n",
      "1     0.051915  0.002751  0.421770  0.000463  0.018043  \n",
      "2     0.066547  0.003509  0.427147  0.000252  0.012968  \n",
      "3     0.022401  0.006362  0.457890  0.000196  0.019336  \n",
      "4     0.057185  0.005364  0.332971  0.000404  0.052290  \n",
      "5     0.003399  0.408818  0.001352  0.015665  0.000888  \n",
      "...        ...       ...       ...       ...       ...  \n",
      "1435  0.039068  0.035371  0.326155  0.002003  0.008762  \n",
      "1436  0.005294  0.025205  0.012576  0.001344  0.001346  \n",
      "1437  0.032963  0.003174  0.531231  0.000198  0.009901  \n",
      "1438  0.038384  0.004678  0.510636  0.000153  0.007080  \n",
      "1439  0.064450  0.002081  0.422793  0.000144  0.018549  \n",
      "\n",
      "[1439 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(Ytest,batch_size=32)\n",
    "predictions_df = pd.DataFrame(preds, columns=['c-15', 'c-16', 'c-42', 'c-52', 'c-62', 'c-65', 'c-67', 'c-88', 'c-90', 'c-92', 'c-95'])\n",
    "predictions_df.index = np.arange(1, len(predictions_df) + 1)\n",
    "predictions_df['ID'] = predictions_df.reset_index().index\n",
    "predictions_df.rename_axis('ID', inplace=True)\n",
    "id_col = predictions_df['ID']  # Extract the 'ID' column\n",
    "predictions_df.drop(columns=['ID'], inplace=True)  # Remove 'ID' column from DataFrame\n",
    "predictions_df.insert(0, 'ID', id_col)  # Insert 'ID' column at the beginning\n",
    "print(predictions_df)\n",
    "predictions_df.to_csv('submission.csv', index = False,sep=\",\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4665be3e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-21T23:48:29.886627Z",
     "iopub.status.busy": "2023-11-21T23:48:29.886309Z",
     "iopub.status.idle": "2023-11-21T23:48:29.900363Z",
     "shell.execute_reply": "2023-11-21T23:48:29.899610Z"
    },
    "papermill": {
     "duration": 0.044321,
     "end_time": "2023-11-21T23:48:29.902049",
     "exception": false,
     "start_time": "2023-11-21T23:48:29.857728",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        ID      c-15      c-16      c-42      c-52      c-62      c-65  \\\n",
      "0        0  0.007671  0.014225  0.251205  0.063879  0.091716  0.076363   \n",
      "1        1  0.008125  0.013665  0.224872  0.038708  0.138407  0.065798   \n",
      "2        2  0.030555  0.011976  0.271053  0.040771  0.063353  0.076106   \n",
      "3        3  0.005473  0.016339  0.299360  0.047871  0.146319  0.036423   \n",
      "4        4  0.002148  0.414180  0.000993  0.000449  0.000928  0.151181   \n",
      "...    ...       ...       ...       ...       ...       ...       ...   \n",
      "1434  1434  0.019370  0.149233  0.132818  0.011300  0.032539  0.243381   \n",
      "1435  1435  0.002675  0.736727  0.012920  0.001030  0.005467  0.195414   \n",
      "1436  1436  0.015176  0.010518  0.196329  0.046280  0.067009  0.087222   \n",
      "1437  1437  0.013031  0.015026  0.161225  0.030233  0.088651  0.130902   \n",
      "1438  1438  0.008143  0.005977  0.258396  0.062105  0.114297  0.043067   \n",
      "\n",
      "          c-67      c-88      c-90      c-92      c-95  \n",
      "0     0.051915  0.002751  0.421770  0.000463  0.018043  \n",
      "1     0.066547  0.003509  0.427147  0.000252  0.012968  \n",
      "2     0.022401  0.006362  0.457890  0.000196  0.019336  \n",
      "3     0.057185  0.005364  0.332971  0.000404  0.052290  \n",
      "4     0.003399  0.408818  0.001352  0.015665  0.000888  \n",
      "...        ...       ...       ...       ...       ...  \n",
      "1434  0.039068  0.035371  0.326155  0.002003  0.008762  \n",
      "1435  0.005294  0.025205  0.012576  0.001344  0.001346  \n",
      "1436  0.032963  0.003174  0.531231  0.000198  0.009901  \n",
      "1437  0.038384  0.004678  0.510636  0.000153  0.007080  \n",
      "1438  0.064450  0.002081  0.422793  0.000144  0.018549  \n",
      "\n",
      "[1439 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"submission.csv\")\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "tpu1vmV38",
   "dataSources": [
    {
     "databundleVersionId": 6978984,
     "sourceId": 63792,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30587,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 48.012117,
   "end_time": "2023-11-21T23:48:33.189155",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-11-21T23:47:45.177038",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
